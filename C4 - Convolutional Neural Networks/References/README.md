# References

<div data-testid="cml-viewer" class="css-1474zrz"><h3><span><strong><span>Week 1:</span></strong></span></h3><ul><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://www.tensorflow.org/guide/keras/sequential_model" class="css-o9h0g5" tabindex="0"><span><span>The Sequential model</span></span><svg aria-labelledby="cds-react-aria-238-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-238"><title id="cds-react-aria-238-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (TensorFlow Documentation)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://www.tensorflow.org/guide/keras/functional" class="css-o9h0g5" tabindex="0"><span><span>The Functional API</span></span><svg aria-labelledby="cds-react-aria-239-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-239"><title id="cds-react-aria-239-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (TensorFlow Documentation)</span></span></p></li></ul><h3><span><strong><span>Week 2:</span></strong></span></h3><ul><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://arxiv.org/abs/1512.03385" class="css-o9h0g5" tabindex="0"><span><span>Deep Residual Learning for Image Recognition</span></span><svg aria-labelledby="cds-react-aria-240-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-240"><title id="cds-react-aria-240-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (He, Zhang, Ren &amp; Sun, 2015)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py" class="css-o9h0g5" tabindex="0"><span><span>deep-learning-models/resnet50.py/</span></span><svg aria-labelledby="cds-react-aria-241-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-241"><title id="cds-react-aria-241-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (GitHub: fchollet)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://arxiv.org/abs/1704.04861" class="css-o9h0g5" tabindex="0"><span><span>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</span></span><svg aria-labelledby="cds-react-aria-242-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-242"><title id="cds-react-aria-242-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (Howard,&nbsp;Zhu, Chen,&nbsp;Kalenichenko,&nbsp;Wang,&nbsp;Weyand,&nbsp;Andreetto,&nbsp;&amp; Adam, 2017)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://arxiv.org/abs/1801.04381" class="css-o9h0g5" tabindex="0"><span><span>MobileNetV2: Inverted Residuals and Linear Bottlenecks</span></span><svg aria-labelledby="cds-react-aria-243-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-243"><title id="cds-react-aria-243-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (Sandler,&nbsp;Howard,&nbsp;Zhu, Zhmoginov &amp;Chen, 2018)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://arxiv.org/abs/1905.11946" class="css-o9h0g5" tabindex="0"><span><span>EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</span></span><svg aria-labelledby="cds-react-aria-244-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-244"><title id="cds-react-aria-244-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (Tan &amp; Le, 2019)</span></span></p></li></ul><h3><span><strong><span>Week 3:</span></strong></span></h3><ul><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://arxiv.org/abs/1506.02640" class="css-o9h0g5" tabindex="0"><span><span>You Only Look Once: Unified, Real-Time Object Detection</span></span><svg aria-labelledby="cds-react-aria-245-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-245"><title id="cds-react-aria-245-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (Redmon,&nbsp;Divvala,&nbsp;Girshick &amp; Farhadi, 2015)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://arxiv.org/abs/1612.08242" class="css-o9h0g5" tabindex="0"><span><span>YOLO9000: Better, Faster, Stronger</span></span><svg aria-labelledby="cds-react-aria-246-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-246"><title id="cds-react-aria-246-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (Redmon &amp; Farhadi, 2016)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://github.com/allanzelener/YAD2K" class="css-o9h0g5" tabindex="0"><span><span>YAD2K</span></span><svg aria-labelledby="cds-react-aria-247-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-247"><title id="cds-react-aria-247-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (GitHub: allanzelener)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://pjreddie.com/darknet/yolo/" class="css-o9h0g5" tabindex="0"><span><span>YOLO: Real-Time Object Detection</span></span><svg aria-labelledby="cds-react-aria-248-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-248"><title id="cds-react-aria-248-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span></span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://arxiv.org/abs/1701.08816" class="css-o9h0g5" tabindex="0"><span><span>Fully Convolutional Architectures for Multi-Class Segmentation in Chest Radiographs</span></span><svg aria-labelledby="cds-react-aria-249-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-249"><title id="cds-react-aria-249-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (Novikov, Lenis,&nbsp;Major,&nbsp;Hladůvka,&nbsp;Wimmer &amp; Bühler, 2017)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://arxiv.org/abs/1705.03820" class="css-o9h0g5" tabindex="0"><span><span>Automatic Brain Tumor Detection and Segmentation Using U-Net Based Fully Convolutional Networks</span></span><svg aria-labelledby="cds-react-aria-250-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-250"><title id="cds-react-aria-250-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (Dong,&nbsp;Yang,&nbsp;Liu,&nbsp;Mo&nbsp;&amp; Guo, 2017)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://arxiv.org/abs/1505.04597" class="css-o9h0g5" tabindex="0"><span><span>U-Net: Convolutional Networks for Biomedical Image Segmentation</span></span><svg aria-labelledby="cds-react-aria-251-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-251"><title id="cds-react-aria-251-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (Ronneberger,&nbsp;Fischer &amp; Brox, 2015)</span></span></p></li></ul><h3><span><strong><span>Week 4:</span></strong></span></h3><ul><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://arxiv.org/pdf/1503.03832.pdf" class="css-o9h0g5" tabindex="0"><span><span>FaceNet: A Unified Embedding for Face Recognition and Clustering</span></span><svg aria-labelledby="cds-react-aria-252-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-252"><title id="cds-react-aria-252-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (Schroff, Kalenichenko &amp; Philbin, 2015)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf" class="css-o9h0g5" tabindex="0"><span><span>DeepFace: Closing the Gap to Human-Level Performance in Face Verification</span></span><svg aria-labelledby="cds-react-aria-253-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-253"><title id="cds-react-aria-253-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (Taigman, Yang, Ranzato &amp; Wolf)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://github.com/davidsandberg/facenet" class="css-o9h0g5" tabindex="0"><span><span>facenet</span></span><svg aria-labelledby="cds-react-aria-254-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-254"><title id="cds-react-aria-254-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (GitHub: davidsandberg)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://machinelearningmastery.com/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier/" class="css-o9h0g5" tabindex="0"><span><span>How to Develop a Face Recognition System Using FaceNet in Keras</span></span><svg aria-labelledby="cds-react-aria-255-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-255"><title id="cds-react-aria-255-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (Jason Brownlee, 2019)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://github.com/nyoki-mtl/keras-facenet/blob/master/notebook/tf_to_keras.ipynb" class="css-o9h0g5" tabindex="0"><span><span>keras-facenet/notebook/tf_to_keras.ipynb</span></span><svg aria-labelledby="cds-react-aria-256-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-256"><title id="cds-react-aria-256-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (GitHub: nyoki-mtl)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://arxiv.org/abs/1508.06576" class="css-o9h0g5" tabindex="0"><span><span>A Neural Algorithm of Artistic Style</span></span><svg aria-labelledby="cds-react-aria-257-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-257"><title id="cds-react-aria-257-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (Gatys, Ecker &amp; Bethge, 2015)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://harishnarayanan.org/writing/artistic-style-transfer/" class="css-o9h0g5" tabindex="0"><span><span>Convolutional neural networks for artistic style transfer</span></span><svg aria-labelledby="cds-react-aria-258-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-258"><title id="cds-react-aria-258-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span></span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style" class="css-o9h0g5" tabindex="0"><span><span>TensorFlow Implementation of "A Neural Algorithm of Artistic Style"</span></span><svg aria-labelledby="cds-react-aria-259-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-259"><title id="cds-react-aria-259-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span></span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://arxiv.org/pdf/1409.1556.pdf" class="css-o9h0g5" tabindex="0"><span><span>Very Deep Convolutional Networks For Large-Scale Image Recognition</span></span><svg aria-labelledby="cds-react-aria-260-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-260"><title id="cds-react-aria-260-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (Simonyan &amp; Zisserman, 2015)</span></span></p></li><li><p><span><span></span></span><span><a target="_blank" rel="noopener nofollow noreferrer" href="https://www.vlfeat.org/matconvnet/pretrained/" class="css-o9h0g5" tabindex="0"><span><span>Pretrained models</span></span><svg aria-labelledby="cds-react-aria-261-title" fill="none" focusable="false" height="16" role="img" viewBox="0 0 16 16" width="16" class="css-8blerm" id="cds-react-aria-261"><title id="cds-react-aria-261-title">Opens in a new tab</title><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 3.5H6v1H2.5v9h9V10h1v4.5h-11v-11zM13.5 2.5H10v-1h4.5V6h-1V2.5z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.646 8.646l7-7 .708.708-7 7-.708-.708z" fill="currentColor"></path></svg></a></span><span><span> (MatConvNet)</span></span></p></li></ul><p><span><span></span></span></p><p><span><span></span></span></p><p><span><span></span></span></p><p><span><span></span></span></p><p><span><span></span></span></p><p><span><span></span></span></p><p><span><span></span></span></p><p><span><span></span></span></p><p><span><span></span></span></p><p><span><span></span></span></p><p><span><span></span></span></p><p><span><span></span></span></p><p><span><span></span></span></p></div>
